# -*- coding: utf-8 -*-
"""FP-SANBERCODE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iZSE8s44v003S4dLFYFSTFaNGt4nYuIY

# SANBERCODE PYTHON - DATA SCIENCE : FINAL PROJECT

## 1 - Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

"""## 2 - Dataset Understanding"""

# Import dataset
df = pd.read_csv('/content/Data_Negara_HELP.csv')
df

df.info()

"""The dataset consists of 167 rows and 10 columns

## 3 - EDA Part 1

### Multivariate analysis by pairplot
"""

# MULTIVARIATE ANALYSIS by pairplot
plt.figure()
sns.pairplot(df)
plt.show()

"""### Multivariate analysis by heatmap"""

# Multivariate analysis by heatmap
plt.figure()
sns.heatmap(df.corr(), annot=True)
plt.show()

"""The correlation score between variables, the closer the correlation score to 0 indicates the weaker correlation.
While the negative correlation score is a contrary relationship between two variables

## 4 - Feature Selection

According to correlation heatmap, the "Inflasi" and "Kematian_anak" features have a correlation score of 0.29.

These two features are sufficient to represent the socioeconomic and health of a country.
Therefore the two features of the dataset will be used as the basis for analysis and clustering.

### Data Cleaning
"""

# New dataframe contains columns "Inflasi" and "Kematian_anak" 

df_new = df[['Negara','Inflasi','Kematian_anak']]

"""#### Missing values"""

# Checking missing values from df_new
df_new.isnull().sum()

"""No missing values

#### Outliers

##### Cheking Outliers
"""

# Cek Outliers from Inflasi
plt.figure()
sns.boxplot(df_new['Inflasi'])

# Cek Outliers from Kematian_anak
plt.figure()
sns.boxplot(df_new['Kematian_anak'])

"""There are outlier values in the "Inflasi" and "Kematian_anak" features.

##### Handling Outliers
"""

# Handling outliers from Inflasi
Q1_i = df_new['Inflasi'].quantile(0.25) 
Q3_i = df_new['Inflasi'].quantile(0.75)
IQR_i = Q3_i - Q1_i

lower_bound_i = Q1_i - (1.5*IQR_i)
upper_bound_i = Q3_i + (1.5*IQR_i)

df_new['Inflasi'].mask((df_new['Inflasi'] > upper_bound_i), upper_bound_i, inplace=True)

# Rechecking after handling
plt.figure()
sns.boxplot(df_new['Inflasi'])

# Handling outliers from Kematian_anak
Q1_k = df_new['Kematian_anak'].quantile(0.25)
Q3_k = df_new['Kematian_anak'].quantile(0.75)
IQR_k = Q3_k - Q1_k

lower_bound_k = Q1_k - (1.5*IQR_k)
upper_bound_k = Q3_k + (1.5*IQR_k)

df_new['Kematian_anak'].mask((df_new['Kematian_anak'] > upper_bound_k), upper_bound_k, inplace=True)

# Recheking after handling
plt.figure()
sns.boxplot(df_new['Kematian_anak'])

"""## 5 - EDA Part 2

### Univariate analysis
"""

# List of conditions
conditions = [
    (df_new['Inflasi'] < 0),
    (df_new['Inflasi'] == 0),
    (df_new['Inflasi'] > 0)
    ]
# List of values
values = ['Deflation', 'Zero Inflation', 'Inflation']

df_new['Category'] = np.select(conditions, values)

df_uni=df_new.groupby(['Category']).count()

plt.pie(df_uni['Inflasi'], labels=df_uni.index, autopct='%1.1f%%')
plt.show()

df_hist=df_new[(df_new['Category'] == 'Inflation')]
plt.figure()
plt.hist(df_hist['Kematian_anak'])
plt.show()

"""### Bivariate analysis"""

plt.figure()
df_new.plot.hexbin(x='Kematian_anak', y='Inflasi', gridsize=15)
plt.xlabel('Kematian_anak')

"""## 6 - Clustering

### Data Scaling
"""

sc = StandardScaler()
scaled = sc.fit_transform(df_new[['Inflasi','Kematian_anak']].astype(float))
scaled_df = pd.DataFrame(data = scaled, columns = ['Inflasi','Kematian_anak'])
scaled_df

"""### Decide The Number of Clusters

#### a. Elbow method
"""

wcss = []
for k in range(1,11):
  kmeans = KMeans(n_clusters = k,init='k-means++', random_state=42)
  kmeans.fit(scaled_df)
  wcss.append(kmeans.inertia_)
plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

"""#### b. Silhouette score method"""

data = []
k_list = []

for k in range(2, 11):
    kmeans = KMeans(n_clusters = k,init='k-means++', random_state=42).fit(scaled_df)
    labels = kmeans.labels_
    data.append(silhouette_score(scaled_df, labels, metric = 'euclidean'))
    k_list.append(k)

plt.plot(k_list,data)
plt.title('Silhouette Score Method')
plt.xlabel('Number of Cluster (k)')
plt.ylabel('Silhouette Score')

"""According to the Elbow method and Silhoutte score, the best number of cluster is "3"

### Clustering Result
"""

kmeans1 = KMeans(n_clusters=4, random_state=42).fit(scaled)
labels1 = kmeans1.labels_
scaled_df['label_kmeans1'] = labels1

plt.figure(figsize=(10,7))
plt.scatter(scaled_df.Inflasi[scaled_df.label_kmeans1 == 0], scaled_df['Kematian_anak'][scaled_df.label_kmeans1 == 0], c='blue', s=100, edgecolors='black', linestyle='-')
plt.scatter(scaled_df.Inflasi[scaled_df.label_kmeans1 == 1], scaled_df['Kematian_anak'][scaled_df.label_kmeans1 == 1], c='red', s=100, edgecolors='black', linestyle='-')
plt.scatter(scaled_df.Inflasi[scaled_df.label_kmeans1 == 2], scaled_df['Kematian_anak'][scaled_df.label_kmeans1 == 2], c='yellow', s=100, edgecolors='black', linestyle='-')
plt.scatter(scaled_df.Inflasi[scaled_df.label_kmeans1 == 3], scaled_df['Kematian_anak'][scaled_df.label_kmeans1 == 3], c='green', s=100, edgecolors='black', linestyle='-')

plt.axhline(c='black')
plt.axvline(c='black')

centers1 = kmeans1.cluster_centers_
plt.scatter(centers1[:, 0], centers1[:, 1], c='black', s=500);
plt.xlabel('Inflasi')
plt.ylabel('Kematian_anak')
plt.xlim(xmin=-3, xmax=3)
plt.ylim(ymin=-3, ymax=3)
plt.title('k-means clustering countries by inflation and child mortality', loc='center', c='blue')
plt.show()

"""## Recommendation

### List of Countries in green cluster
"""

new = scaled_df.assign(Negara=df_new['Negara'],
                       OR_Inflasi=df_new['Inflasi'],
                       OR_Kematian_anak=df_new['Kematian_anak'])

filter_df=new[new.label_kmeans1 == 3].sort_values(by=['Kematian_anak','Inflasi'], ascending=False).drop(['Inflasi','Kematian_anak','label_kmeans1'], axis=1).rename(columns={"OR_Inflasi":"Inflasi", "OR_Kematian_anak":"Kematian_anak"})
filter_df

"""### List of Countries with low "GDPperkapita"
"""

df_GDP = df[['Negara','Pendapatan','GDPperkapita']].sort_values(by='GDPperkapita').head()

df_GDP.set_index('Negara')

"""### Recommended Countries"""

rec = filter_df.merge(df_GDP, how='inner', on='Negara')
rec.set_index("Negara")